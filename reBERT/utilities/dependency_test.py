# dependency_test.py - Comprehensive dependency and functionality test for src project

import sys
import tomllib
import re
from pathlib import Path
from typing import Dict, Any
import warnings

warnings.filterwarnings("ignore")  # Suppress minor warnings for cleaner output


def parse_pyproject_dependencies() -> Dict[str, str]:
    """Parse expected versions from pyproject.toml"""

    # Look for pyproject.toml in current directory or parent directory
    pyproject_path = None
    for path in [Path("../../pyproject.toml"), Path("../../pyproject.toml")]:
        if path.exists():
            pyproject_path = path
            break

    if not pyproject_path:
        print("‚ùå Could not find pyproject.toml file")
        return {}

    try:
        with open(pyproject_path, "rb") as f:
            pyproject_data = tomllib.load(f)

        dependencies = pyproject_data.get("project", {}).get("dependencies", [])

        expected_versions = {}
        for dep in dependencies:
            # Parse dependency strings like "numpy==2.3.0" or "torch==2.6.0+cu124"
            if "==" in dep:
                name, version = dep.split("==", 1)
                # Handle cases like "python-dotenv==1.0.1" -> map to "dotenv" import name
                import_name = name.strip().replace('"', "").replace("'", "")

                # Map package names to import names
                name_mapping = {"python-dotenv": "dotenv", "scikit-learn": "sklearn"}

                import_name = name_mapping.get(import_name, import_name)
                version = version.strip().replace('"', "").replace("'", "").rstrip(",")

                expected_versions[import_name] = version

        print(f"üìÅ Loaded dependencies from: {pyproject_path}")
        print(f"üì¶ Found {len(expected_versions)} dependencies with version pins")

        return expected_versions

    except Exception as e:
        print(f"‚ùå Error parsing pyproject.toml: {e}")
        return {}


def check_version_match(expected: str, actual: str) -> str:
    """Compare expected vs actual version and return status emoji"""
    if expected == "Not specified":
        return "‚úÖ"

    # Extract major.minor from both versions for comparison
    try:
        expected_parts = expected.split(".")
        actual_parts = actual.split(".")

        # Compare major.minor (ignore patch versions and suffixes like +cu124)
        if len(expected_parts) >= 2 and len(actual_parts) >= 2:
            expected_major_minor = f"{expected_parts[0]}.{expected_parts[1]}"
            actual_major_minor = f"{actual_parts[0]}.{actual_parts[1]}"

            if actual_major_minor == expected_major_minor:
                return "‚úÖ"
            else:
                return "‚ö†Ô∏è"
    except:
        pass

    # Fallback: exact match
    return "‚úÖ" if actual == expected else "‚ö†Ô∏è"


def test_package(
    package_name: str, import_name: str, expected_versions: dict, results: dict
) -> bool:
    """Generic function to test a package import and version"""
    try:
        module = __import__(import_name)
        expected = expected_versions.get(package_name, "Not specified")
        actual = getattr(module, "__version__", "Unknown")
        status = check_version_match(expected, actual)

        results[package_name] = {"expected": expected, "actual": actual, "status": status}
        print(f"{package_name.title()}: Expected {expected}, Got {actual} {status}")
        return True

    except Exception as e:
        results[package_name] = {"error": str(e)}
        print(f"‚ùå {package_name.title()} failed: {e}")
        return False


def test_versions_and_functionality():
    """Test all dependencies with expected vs actual versions and basic functionality"""

    print("üß™ src Project Dependency & Functionality Test")
    print("=" * 60)
    print(f"Python version: {sys.version}")
    print("=" * 60)

    # Parse expected versions from pyproject.toml
    expected_versions = parse_pyproject_dependencies()

    if not expected_versions:
        print("‚ùå No dependencies found in pyproject.toml - cannot run tests")
        return

    results = {}

    # Core Data Science Packages
    print("\nüìä CORE DATA SCIENCE PACKAGES")
    print("-" * 40)

    # NumPy
    if test_package("numpy", "numpy", expected_versions, results):
        try:
            import numpy as np

            arr = np.array([1, 2, 3, 4, 5])
            assert arr.mean() == 3.0, "NumPy basic operations failed"
            print("  ‚úÖ NumPy array operations working")
        except Exception as e:
            print(f"  ‚ùå NumPy functionality test failed: {e}")

    # Pandas
    if test_package("pandas", "pandas", expected_versions, results):
        try:
            import pandas as pd

            df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
            assert len(df) == 3, "Pandas DataFrame creation failed"
            print("  ‚úÖ Pandas DataFrame operations working")
        except Exception as e:
            print(f"  ‚ùå Pandas functionality test failed: {e}")

    # Matplotlib
    if test_package("matplotlib", "matplotlib", expected_versions, results):
        try:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots()
            ax.plot([1, 2, 3], [1, 4, 2])
            plt.close(fig)  # Don't show plot in test
            print("  ‚úÖ Matplotlib plotting working")
        except Exception as e:
            print(f"  ‚ùå Matplotlib functionality test failed: {e}")

    # Seaborn
    if test_package("seaborn", "seaborn", expected_versions, results):
        print("  ‚úÖ Seaborn styling available")

    # Scikit-learn
    if test_package("sklearn", "sklearn", expected_versions, results):
        try:
            from sklearn.datasets import make_classification

            X, y = make_classification(n_samples=100, n_features=4, random_state=42)
            assert X.shape == (100, 4), "Sklearn dataset generation failed"
            print("  ‚úÖ Scikit-learn dataset generation working")
        except Exception as e:
            print(f"  ‚ùå Scikit-learn functionality test failed: {e}")

    # AI/ML Packages
    print("\nü§ñ AI/ML PACKAGES")
    print("-" * 40)

    # PyTorch
    if test_package("torch", "torch", expected_versions, results):
        try:
            import torch

            print(f"  CUDA available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"  GPU: {torch.cuda.get_device_name(0)}")
                print(f"  CUDA version: {torch.version.cuda}")

            # Test tensor operations
            x = torch.randn(3, 4)
            y = torch.randn(4, 5)
            z = torch.mm(x, y)
            assert z.shape == (3, 5), "PyTorch tensor operations failed"
            print("  ‚úÖ PyTorch tensor operations working")

            # Test GPU if available
            if torch.cuda.is_available():
                x_gpu = x.cuda()
                assert x_gpu.is_cuda, "GPU tensor transfer failed"
                print("  ‚úÖ PyTorch GPU operations working")

        except Exception as e:
            print(f"  ‚ùå PyTorch functionality test failed: {e}")

    # Transformers
    if test_package("transformers", "transformers", expected_versions, results):
        try:
            from transformers import AutoTokenizer

            tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
            tokens = tokenizer("Hello world!")
            assert "input_ids" in tokens, "Transformers tokenization failed"
            print("  ‚úÖ Transformers tokenization working")
        except Exception as e:
            print(f"  ‚ùå Transformers functionality test failed: {e}")

    # Accelerate
    if test_package("accelerate", "accelerate", expected_versions, results):
        print("  ‚úÖ Accelerate available for distributed training")

    # Datasets
    if test_package("datasets", "datasets", expected_versions, results):
        print("  ‚úÖ HuggingFace datasets available")

    # Development Environment
    print("\nüíª DEVELOPMENT ENVIRONMENT")
    print("-" * 40)

    # IPython
    if test_package("ipython", "IPython", expected_versions, results):
        print("  ‚úÖ Interactive Python shell available")

    # JupyterLab
    if test_package("jupyterlab", "jupyterlab", expected_versions, results):
        print("  ‚úÖ JupyterLab environment available")

    # Notebook
    if test_package("notebook", "notebook", expected_versions, results):
        print("  ‚úÖ Classic Jupyter notebook available")

    # Utilities and Tools
    print("\nüõ†Ô∏è UTILITIES AND TOOLS")
    print("-" * 40)

    # Loguru
    if test_package("loguru", "loguru", expected_versions, results):
        try:
            from loguru import logger

            logger.info("Test log message")
            print("  ‚úÖ Loguru logging working")
        except Exception as e:
            print(f"  ‚ùå Loguru functionality test failed: {e}")

    # Python-dotenv (maps to 'dotenv' import)
    if test_package("dotenv", "dotenv", expected_versions, results):
        print("  ‚úÖ Environment variable loading available")

    # Tqdm
    if test_package("tqdm", "tqdm", expected_versions, results):
        try:
            from tqdm import tqdm as progress_bar

            for i in progress_bar(range(3), desc="Testing tqdm"):
                pass
            print("  ‚úÖ Progress bars working")
        except Exception as e:
            print(f"  ‚ùå Tqdm functionality test failed: {e}")

    # Typer
    if test_package("typer", "typer", expected_versions, results):
        print("  ‚úÖ CLI framework available")

    # Ruff
    if test_package("ruff", "ruff", expected_versions, results):
        print("  ‚úÖ Code linting and formatting available")

    # Documentation
    print("\nüìö DOCUMENTATION")
    print("-" * 40)

    # MkDocs
    if test_package("mkdocs", "mkdocs", expected_versions, results):
        print("  ‚úÖ Documentation generator available")

    # Summary
    print("\n" + "=" * 60)
    print("üìã SUMMARY")
    print("=" * 60)

    success_count = sum(1 for r in results.values() if "status" in r and r["status"] == "‚úÖ")
    warning_count = sum(1 for r in results.values() if "status" in r and r["status"] == "‚ö†Ô∏è")
    error_count = sum(1 for r in results.values() if "error" in r)
    total_count = len(results)

    print(f"‚úÖ Success: {success_count}/{total_count}")
    print(f"‚ö†Ô∏è  Warnings: {warning_count}/{total_count}")
    print(f"‚ùå Errors: {error_count}/{total_count}")

    if error_count == 0 and warning_count <= 2:
        print("\nüéâ Environment is ready for src development!")
    elif error_count == 0:
        print("\n‚úÖ Environment is mostly ready - check version warnings")
    else:
        print("\n‚ö†Ô∏è  Some dependencies failed - check errors above")

    return results

if __name__ == "__main__":
    test_versions_and_functionality()